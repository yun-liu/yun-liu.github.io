<!DOCTYPE html>
<!--[if IE 8]>
  <html lang="en" class="ie8">
<![endif]-->
<!--[if IE 9]>
  <html lang="en" class="ie9">
<![endif]-->
<!--[if !IE]><!-->
<html lang="en">
  <!--<![endif]-->
  <head>
    <title>Yun Liu</title>
    <!-- Meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,Chrome=1">
    <!-- <meta name="viewport" content="width=device-width, initial-scale=1.0">-->
    <meta name="description" content="Yun Liu's homepage">
    <link rel="shortcut icon" href="assets/imgs/logo2.jpg">
    <link href='https://fonts.googleapis.com/css?family=Roboto:400,500,400italic,300italic,300,500italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
    <!-- Global CSS -->
    <link rel="stylesheet" href="assets/css/bootstrap.min.css">
    <link rel="stylesheet" href="assets/css/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="assets/css/main.css">
    <script src="bootstrap/js/bootstrap.min.js"></script>
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-88572407-1', 'auto');
      ga('send', 'pageview');
    </script>
    <meta name="google-site-verification" content="F0Q0t5oLq1pGwXGMf_38oA2MxW_zfiMRsQTYD4_GJoQ" />
  </head>
  <!-- The body of this website -->
  <body>
    <div class="container">
      <div class="row">
        <!-- biography starts here -->
        <div class='row'>
          <div class='col-xs-3'>
              <div class='photo'>
                <img src="assets/imgs/love2.jpg" alt="photo"/>
              </div>
          </div>
          <div class='col-xs-8'>
            <h3>
              Yun Liu (刘云)
            </h3>
            <p>
              I am a PhD student at CCCE&CS, Nankai University (Tianjin, China).
              My advisor is Professor <a href="https://mmcheng.net/cmm/">Ming-Ming Cheng</a>.
              I received my bachelor's degree from Nankai University in 2016.
              My research interest includes computer vision and machine learning (especially deep learning).
            </p>
            <h3 style="padding-top:-5px"></h3>
            <i class="fa fa-envelope"></i> &nbsp;
            <a href="mailto:nk12csly@mail.nankai.edu.cn">nk12csly AT mail DOT nankai DOT edu DOT cn</a>
            &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
            <i class="fa fa-globe"></i> &nbsp;
            <a href="https://scholar.google.com/citations?user=UB3doCoAAAAJ" target="_blank">Google Scholar</a>
            &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
            <object id="object" data="assets/css/github.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
            <a href="https://github.com/yun-liu" target="_blank">Github</a>
          </div>
        </div>
        <!-- biography ends here -->
        <hr>
        <!-- the part of publications starts here -->
        <h3>
          <a name='publications'></a> Publications
        </h3>
        <!-- Journal papers -->
        <h4> Journal </h4>
        <ul>
          <li>
            <p>
              <b>RefinedBox: Refining for Fewer and High-quality Object Proposals</b><br>
              <strong>Yun Liu</strong>, Shi-Jie Li, and Ming-Ming Cheng<br>
              <i>Neurocomputing</i>, 2020<br>
              <a href="https://yun-liu.github.io/papers/(Neurocomputing'2020)RefinedBox%20-%20Refining%20for%20Fewer%20and%20High-quality%20Object%20Proposals.pdf">[PDF]</a>
              <a href="https://github.com/yun-liu/RefinedBox">[Code]</a>
              <a href="https://www.sciencedirect.com/science/article/pii/S0925231220305816">[Official Version]</a>
            </p>
          </li>
          <li>
            <p>
              <b>Ordered or Orderless: A Revisit for Video based Person Re-Identification</b><br>
              Le Zhang, Zenglin Shi, Joey Tianyi Zhou, Ming-Ming Cheng, <strong>Yun Liu</strong>, Jia-Wang Bian, Zeng Zeng, and Chunhua Shen<br>
              <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2020<br>
              <a href="https://yun-liu.github.io/papers/(TPAMI'2020)Ordered%20or%20Orderless%20-%20A%20Revisit%20for%20Video%20based%20Person%20Re-Identification.pdf">[PDF]</a>
              <a href="https://github.com/ZhangLeUestc/VideoReid-TPAMI2020">[Code]</a>
              [Official Version]
            </p>
          </li>
          <li>
            <p>
              <b>Nonlinear Regression via Deep Negative Correlation Learning</b><br>
              Le Zhang, Zenglin Shi, Ming-Ming Cheng, <strong>Yun Liu</strong>, Jia-Wang Bian, Joey Tianyi Zhou, Guoyan Zheng, and Zeng Zeng<br>
              <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2020<br>
              <a href="https://yun-liu.github.io/papers/(TPAMI'2020)Nonlinear%20Regression%20via%20Deep%20Negative%20Correlation%20Learning.pdf">[PDF]</a>
              <a href="https://mmcheng.net/dncl/">[Project Page]</a>
              <a href="https://github.com/shizenglin/Deep-NCL">[Code]</a>
              [Official Version]
            </p>
          </li>
          <li>
            <p>
              <b>GMS: Grid-based Motion Statistics for Fast, Ultra-robust Feature Correspondence</b><br>
              Jia-Wang Bian, Wen-Yan Lin, <strong>Yun Liu</strong>, Le Zhang, Sai-Kit Yeung, Ming-Ming Cheng, and Ian Reid<br>
              <i>International Journal of Computer Vision (IJCV)</i>, 2020<br>
              <a href="https://yun-liu.github.io/papers/(IJCV'2020)GMS%20-%20Grid-based%20Motion%20Statistics%20for%20Fast%2C%20Ultra-robust%20Feature%20Correspondence.pdf">[PDF]</a>
              <a href="http://jwbian.net/gms">[Project Page]</a>
              <a href="https://github.com/JiawangBian/GMS-Feature-Matcher">[Code]</a>
              <a href="https://www.youtube.com/watch?v=3SlBqspLbxI&feature=youtu.be">[YouTube]</a>
              <a href="https://link.springer.com/article/10.1007%2Fs11263-019-01280-3">[Official Version]</a>
            </p>
          </li>
          <li>
            <p>
              <b>Richer Convolutional Features for Edge Detection</b><br>
              <strong>Yun Liu</strong>, Ming-Ming Cheng, Xiaowei Hu, Jia-Wang Bian, Le Zhang, Xiang Bai, and Jinhui Tang<br>
              <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2019<br>
              <a href="https://yun-liu.github.io/papers/(TPAMI'2019)Richer%20Convolutional%20Features%20for%20Edge%20Detection.pdf">[PDF]</a>
              <a href="https://mmcheng.net/rcfedge/">[Project Page]</a>
              <a href="https://github.com/yun-liu/rcf">[Code]</a>
              <a href="https://ieeexplore.ieee.org/document/8516362">[Official Version]</a>
            </p>
          </li>
          <li>
            <p>
              <b>BING: Binarized Normed Gradients for Objectness Estimation at 300fps</b><br>
              Ming-Ming Cheng*, <strong>Yun Liu*</strong>, Wen-Yan Lin, Ziming Zhang,  Paul L. Rosin, and Philip H. S. Torr<br>
              <b>(* indicates joint first authors)</b><br>
              <i>Computational Visual Media (CVM)</i>, 2019<br>
              <a href="https://yun-liu.github.io/papers/(CVM'2018)BING%20-%20Binarized%20Normed%20Gradients%20for%20Objectness%20Estimation%20at%20300fps.pdf">[PDF]</a>
              <a href="https://mmcheng.net/zh/bing/">[Project Page]</a>
              <a href="https://github.com/yun-liu/bing">[Code]</a>
              <a href="https://link.springer.com/article/10.1007/s41095-018-0120-1">[Official Version]</a>
            </p>
          </li>
          <li>
            <p>
              <b>Sequential Optimization for Efficient High-Quality Object Proposal Generation</b><br>
              Ziming Zhang, <strong>Yun Liu</strong>, Xi Chen, Yanjun Zhu, Ming-Ming Cheng, Venkatesh Saligrama, and Philip H.S. Torr<br>
              <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2018<br>
              <a href="https://yun-liu.github.io/papers/(TPAMI'2018)Sequential%20Optimization%20for%20Efficient%20High-Quality%20Object%20Proposal%20Generation.pdf">[PDF]</a>
              <a href="https://pan.baidu.com/s/1slEK7Q9?errno=0&errmsg=Auth%20Login%20Sucess&&bduss=&ssnerror=0">[Code]</a>
              <a href="https://ieeexplore.ieee.org/document/7932893">[Official Version]</a>
            </p>
          </li>
        </ul>
        <!-- conference papers -->
        <h4> Conference </h4>
        <ul>
          <li>
            <p>
              <b>Rethinking Computer-aided Tuberculosis Diagnosis</b><br>
              <strong>Yun Liu*</strong>, Yu-Huan Wu*, Yunfeng Ban, Huifang Wang, and Ming-Ming Cheng<br>
              <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR, <strong>Oral</strong>)</i>, 2020<br>
              <a href="https://yun-liu.github.io/papers/(CVPR'2020)Rethinking%20Computer-aided%20Tuberculosis%20Diagnosis.pdf">[PDF]</a>
              <a href="https://mmcheng.net/tb/">[Project Page]</a>
              <a href="http://openaccess.thecvf.com/content_CVPR_2020/html/Liu_Rethinking_Computer-Aided_Tuberculosis_Diagnosis_CVPR_2020_paper.html">[Official Version]</a>
            </p>
          </li>
          <li>
            <p>
              <b>Pyramid Constrained Self-Attention Network for Fast Video Salient Object Detection</b><br>
              Yuchao Gu, Lijuan Wang, Ziqin Wang, <strong>Yun Liu</strong>, Ming-Ming Cheng, and Shao-Ping Lu<br>
              <i>AAAI Conference on Artificial Intelligence (AAAI)</i>, 2020<br>
              <a href="https://yun-liu.github.io/papers/(AAAI'2020)Pyramid%20Constrained%20Self-Attention%20Network%20for%20Fast%20Video%20Salient%20Object%20Detection.pdf">[PDF]</a>
              <a href="http://mmcheng.net/pcsa/">[Project Page]</a>
              <a href="https://github.com/guyuchao/PyramidCSA">[Code]</a>
              <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6718">[Official Version]</a>
            </p>
          </li>
          <li>
            <p>
              <b>Multi-Level Context Ultra-Aggregation for Stereo Matching</b><br>
              Guang-Yu Nie, Ming-Ming Cheng, <strong>Yun Liu</strong>, Zhengfa Liang, Deng-Ping Fan, Yue Liu, and Yongtian Wang<br>
              <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2019<br>
              <a href="https://yun-liu.github.io/papers/(CVPR'2019)Multi-Level%20Context%20Ultra-Aggregation%20for%20Stereo%20Matching.pdf">[PDF]</a>
              <a href="https://mmcheng.net/mcua/">[Project Page]</a>
              <a href="https://yun-liu.github.io/material/CVPR2019_MCUA_Supplementary.pdf">[Supplementary Materials]</a>
              <a href="https://yun-liu.github.io/material/CVPR2019_MCUA_PPT.pdf">[PPT]</a>
              <a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Nie_Multi-Level_Context_Ultra-Aggregation_for_Stereo_Matching_CVPR_2019_paper.html">[Official Version]</a>
            </p>
          </li>
          <li>
            <p>
              <b>DEL: Deep Embedding Learning for Efficient Image Segmentation</b><br>
              <strong>Yun Liu</strong>, Peng-Tao Jiang, Vahan Petrosyan, Shi-Jie Li, Jiawang Bian, Le Zhang, and Ming-Ming Cheng<br>
              <i>International Joint Conference on Artificial Intelligence (IJCAI)</i>, 2018<br>
              <a href="https://yun-liu.github.io/papers/(IJCAI'2018)DEL%20-%20Deep%20Embedding%20Learning%20for%20Efficient%20Image%20Segmentation.pdf">[PDF]</a>
              <a href="https://mmcheng.net/del/">[Project Page]</a>
              <a href="https://github.com/yun-liu/del">[Code]</a>
              <a href="https://www.ijcai.org/proceedings/2018/120">[Official Version]</a>
            </p>
          </li>
          <li>
            <p>
              <b>Crowd Counting with Deep Negative Correlation Learning</b><br>
              Zenglin Shi, Le Zhang, <strong>Yun Liu</strong>, XiaoFeng Cao, Yangdong Ye, Ming-Ming Cheng, and Guoyan Zheng<br>
              <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2018<br>
              <a href="https://yun-liu.github.io/papers/(CVPR'2018)Crowd%20Counting%20with%20Deep%20Negative%20Correlation%20Learning.pdf">[PDF]</a>
              <a href="https://sites.google.com/site/zhangleuestc/crowd-counting-with-deep-negative-learning/crowd-counting-with-deep-negative-learning">[Project Page]</a>
              <a href="https://github.com/shizenglin/Deep-NCL">[Code]</a>
              <a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Crowd_Counting_via_CVPR_2018_paper.html">[Official Version]</a>
            </p>
          </li>
          <li>
            <p>
              <b>Structure-measure: A New Way to Evaluate Foreground Maps</b><br>
              DengPing Fan, Ming-Ming Cheng, <strong>Yun Liu</strong>, Tao Li, and Ali Borji<br>
              <i>International Conference on Computer Vision (ICCV)</i>, 2017<br>
              <a href="https://yun-liu.github.io/papers/(ICCV'2017)Structure-measure%20-%20A%20New%20Way%20to%20Evaluate%20Foreground%20Maps.pdf">[PDF]</a>
              <a href="http://dpfan.net/smeasure/">[Project Page]</a>
              <a href="https://github.com/DengPingFan/S-measure">[Code]</a>
              <a href="https://yun-liu.github.io/material/ICCV2017-S-measure_PPT.pdf">[PPT]</a>
              <a href="http://openaccess.thecvf.com/content_iccv_2017/html/Fan_Structure-Measure_A_New_ICCV_2017_paper.html">[Official Version]</a>
            </p>
          </li>
          <li>
            <p>
              <b>Richer Convolutional Features for Edge Detection</b><br>
              <strong>Yun Liu</strong>, Ming-Ming Cheng, Xiaowei Hu, Kai Wang, and Xiang Bai<br>
              <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2017<br>
              <a href="https://yun-liu.github.io/papers/(CVPR'2017)Richer%20Convolutional%20Features%20for%20Edge%20Detection.pdf">[PDF]</a>
              <a href="https://mmcheng.net/rcfedge/">[Project Page]</a>
              <a href="https://github.com/yun-liu/rcf">[Code]</a>
              <a href="http://openaccess.thecvf.com/content_cvpr_2017/html/Liu_Richer_Convolutional_Features_CVPR_2017_paper.html">[Official Version]</a>
            </p>
          </li>
          <li>
            <p>
              <b>HFS: Hierarchical Feature Selection for Efficient Image Segmentation</b><br>
              Ming-Ming Cheng*, <strong>Yun Liu*</strong>, Qibin Hou, Jiawang Bian, Philip Torr, Shi-Min Hu, and Zhuowen Tu<br>
              <b>(* indicates joint first authors)</b><br>
              <i>European Conference on Computer Vision (ECCV)</i>, 2016<br>
              <a href="https://yun-liu.github.io/papers/(ECCV'2016)HFS%20-%20Hierarchical%20Feature%20Selection%20for%20Efficient%20Image%20Segmentation.pdf">[PDF]</a>
              <a href="https://mmcheng.net/hfs/">[Project Page]</a>
              <a href="https://github.com/yun-liu/hfs">[Code]</a>
              <a href="https://link.springer.com/chapter/10.1007/978-3-319-46487-9_53">[Official Version]</a>
            </p>
          </li>
        </ul>
        <!-- the part of publications ends here -->
        <hr>
        <!-- the part of professional service starts here -->
        <h3>
          <a name='service'></a> Professional Service
        </h3>
        <div class='service'>
          <ul>
            <li>Conference Reviewer: CVPR 2018-2020, ICCV 2019, ECCV 2020, AAAI 2020, ICPR 2020, ACCV 2018-2020, WACV 2021, PRCV 2018-2020</li>
            <li>Journal Reviewer: IEEE TPAMI, IEEE TIP, IEEE TCSVT, KNOSYS, IEEE CIM, IEEE JBHI, Pattern Recognition, Neurocomputing, SPIC</li>
            <li>Outstanding Reviewer of CVPR 2018</li>
          </ul>
        </div>
        <!-- the part of professional service ends here -->
        <hr>
        <!-- the part of patents starts here -->
        <h3>
          <a name='patents'></a> Patents
        </h3>
        <div class='patents'>
          <ul>
            <li>程明明，刘云，吴宇寰，基于多路割的弱监督实例分割方法，申请号：201910347532.5，申请日：2019-04-28</li>
            <li>程明明，刘云，基于多层次上下文信息融合的显著性物体检测方法，申请号：201811547592.3，申请日：2018-12-18</li>
            <li>程明明，刘云，侯淇彬，白蔚，图像分割方法及装置，申请号：201610850223.6，申请日：2016-09-28</li>
          </ul>
        </div>
        <!-- the part of patents ends here -->
        <hr>
        <!-- the part of awards starts here -->
        <h3>
          <a name='awards'></a> Awards
        </h3>
        <div class='awards'>
          <ul>
            <li>Special Scholarship (Ten Outstanding Students), Nankai University (2019)</li>
            <li>China National Scholarship (2017, 2019)</li>
            <li>"Ming-Shan-Yun-Neng" Scholarship, Nankai University (2016)</li>
            <li>China National Endeavor Scholarship (2013, 2014, 2015)</li>
          </ul>
        </div>
        <!-- the part of awards ends here -->
        <hr>
        <footer class="footer">
          <div class="container">
            <small class="copyright"> 2020 Yun Liu</small>
          </div>
        </footer>
        <div class="container">
          <div style="display:inline-block;width:200px;">
            <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5xe6txh5mnm&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
